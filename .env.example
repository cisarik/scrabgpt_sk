OPENAI_API_KEY='xxx'
AI_MOVE_MAX_OUTPUT_TOKENS='5000'
AI_MOVE_TIMEOUT_SECONDS='120'
JUDGE_MAX_OUTPUT_TOKENS='1800'
OPENROUTER_API_KEY='yyy'
NOVITA_API_KEY='zzz'
AI_PROMPT_FILE='prompts/default.txt'

# === Local LLM Studio Integration ===
# Point OpenAI client to local reasoning models (e.g., deepseek-r1)
# Start llmstudio server: llmstudio serve deepseek/deepseek-r1-0528-qwen3-8b
# OPENAI_BASE_URL='http://localhost:1234/v1'
# LLMSTUDIO_MODEL='deepseek/deepseek-r1-0528-qwen3-8b'

# === Reasoning Model Context Session ===
# Enable persistent context window for huge token savings (80-90% reduction)
# Instead of rebuilding the full prompt every turn, we maintain a rolling conversation
# AI_CONTEXT_SESSION='1'              # Reuse context across turns (1/true/on to enable)
# AI_CONTEXT_HISTORY='8'              # Keep last N turns in memory (1-20, default 8)

# Agent Activity Display
# Set to 'false' to disable automatic showing of agent activity window
# (useful for end users who don't want to see agent thinking process)
SHOW_AGENT_ACTIVITY_AUTO='true'

# Opponent mode configuration
OPENAI_MODELS='gpt-5.2,gpt-5-mini,gpt-4.1'
# Optional: enforce mandatory tool sequence in OpenAI mode (get_board_state -> get_premium_squares)
# OPENAI_ENFORCE_TOOL_WORKFLOW='true'
# Optional: minimum number of dictionary validations before OpenAI finalizes a move
# OPENAI_MIN_WORD_VALIDATIONS='12'
# Optional: minimum number of distinct scored candidates before OpenAI finalizes a move
# OPENAI_MIN_SCORED_CANDIDATES='12'
# Optional: per-request timeout inside OpenAI tool workflow loop (seconds)
# OPENAI_TOOL_ROUND_TIMEOUT_SECONDS='20'
OPENAI_BEST_MODEL_AUTO_UPDATE='false'  # Auto-update to best model: true/false (WARNING: modifies .env)
DEFAULT_OPPONENT_MODE='gemini'  # Default mode: best_model, agent, openrouter, novita, gemini
DEFAULT_AGENT_NAME='Plný Prístup'  # Default agent name for agent mode

GOOGLE_API_KEY='' # Gemini 3 Pro

# === Vertex AI + Gemini (google-genai / Vertex endpoint) ===
# Prefer ADC (Application Default Credentials) or point to a service account JSON:
# gcloud auth application-default login
# OR set GOOGLE_APPLICATION_CREDENTIALS below.
GOOGLE_CLOUD_PROJECT='your-gcp-project-id'
GOOGLE_CLOUD_LOCATION='global'
GEMINI_MODEL='gemini-3.1-pro-preview'
# Optional: comma-separated Gemini candidates for parallel evaluation in Google mode
# GEMINI_MODELS='gemini-3.1-pro-preview,gemini-3-flash-preview,gemini-2.5-pro'
# GOOGLE_APPLICATION_CREDENTIALS='/abs/path/to/service-account.json'
