OPENAI_API_KEY='xxx'
AI_MOVE_MAX_OUTPUT_TOKENS='5000'
AI_MOVE_TIMEOUT_SECONDS='120'
JUDGE_MAX_OUTPUT_TOKENS='1800'
OPENROUTER_API_KEY='yyy'
NOVITA_API_KEY='zzz'
AI_PROMPT_FILE='prompts/default.txt'

# === Local LLM Studio Integration ===
# Point OpenAI client to local reasoning models (e.g., deepseek-r1)
# Start llmstudio server: llmstudio serve deepseek/deepseek-r1-0528-qwen3-8b
# OPENAI_BASE_URL='http://localhost:1234/v1'
# OPENAI_MODEL='deepseek/deepseek-r1-0528-qwen3-8b'

# === Reasoning Model Context Session ===
# Enable persistent context window for huge token savings (80-90% reduction)
# Instead of rebuilding the full prompt every turn, we maintain a rolling conversation
# AI_CONTEXT_SESSION='1'              # Reuse context across turns (1/true/on to enable)
# AI_CONTEXT_HISTORY='8'              # Keep last N turns in memory (1-20, default 8)

# Agent Activity Display
# Set to 'false' to disable automatic showing of agent activity window
# (useful for end users who don't want to see agent thinking process)
SHOW_AGENT_ACTIVITY_AUTO='true'

# Opponent mode configuration
OPENAI_PLAYER_MODEL='gpt-4o-mini'  # Current AI model (auto-updated if enabled below)
OPENAI_BEST_MODEL_AUTO_UPDATE='false'  # Auto-update to best model: true/false (WARNING: modifies .env)
DEFAULT_OPPONENT_MODE='gemini'  # Default mode: best_model, agent, openrouter, novita, gemini
DEFAULT_AGENT_NAME='Plný Prístup'  # Default agent name for agent mode

GOOGLE_API_KEY='' # Gemini 3 Pro

# === Vertex AI + Gemini (google-genai / Vertex endpoint) ===
# Prefer ADC (Application Default Credentials) or point to a service account JSON:
# gcloud auth application-default login
# OR set GOOGLE_APPLICATION_CREDENTIALS below.
GOOGLE_CLOUD_PROJECT='your-gcp-project-id'
GOOGLE_CLOUD_LOCATION='global'
GEMINI_MODEL='gemini-3.1-pro-preview'
# GOOGLE_APPLICATION_CREDENTIALS='/abs/path/to/service-account.json'
